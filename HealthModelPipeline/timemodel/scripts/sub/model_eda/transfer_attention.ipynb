{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "a07c98cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# moduel\n",
    "from my_package.select_dataset_all import get_all_dataframe_from_database\n",
    "import my_package.time_series as time\n",
    "\n",
    "# basic\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "\n",
    "# visualize\n",
    "import matplotlib.pyplot as plt  \n",
    "\n",
    "# learning\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b56efead",
   "metadata": {},
   "source": [
    "<span style=\"color: blue; font-size: 14px; font-weight: bold; background-color: #f0f0f0; padding: 5px; border-radius: 5px;\">\n",
    "    set\n",
    "</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "58e1e17e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# goals: 데이터 생성 \n",
    "\n",
    "data = time.create_electrode_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b1a83deb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# goals: 데이터 처리\n",
    "\n",
    "ship_name = 'MASAN TEST150'\n",
    "\n",
    "ship_id = ship_id = time.find_ship(ship_name)[0]\n",
    "\n",
    "df = time.preprocess_data(data,ship_id)\n",
    "\n",
    "df = time.generate_moving_average(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "29a92603",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pc021\\AppData\\Local\\Temp\\ipykernel_12208\\2710879781.py:3: FutureWarning: The default value of numeric_only in DataFrameGroupBy.mean is deprecated. In a future version, numeric_only will default to False. Either specify numeric_only or select only columns which should be valid for the function.\n",
      "  group = df.groupby(['DATA_TIME']).mean()['ELECTRODE_EFFICIENCY'].to_frame().reset_index()\n"
     ]
    }
   ],
   "source": [
    "# golas: 시간 기준 그룹화\n",
    "\n",
    "group = df.groupby(['DATA_TIME']).mean()['ELECTRODE_EFFICIENCY'].to_frame().reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acb82a63",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "  25/2228 [..............................] - ETA: 2:34:01 - loss: 1156.0520"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "# 데이터 로드\n",
    "# df = pd.read_csv('path_to_your_data.csv')  # 실제 데이터 경로를 입력해 주세요.\n",
    "# 위 데이터를 예로 사용한 더미 데이터 생성\n",
    "\n",
    "# 1. 데이터를 ELECTRODE_EFFICIENCY 값만 추출하여 numpy array로 변환\n",
    "data = group['ELECTRODE_EFFICIENCY'].values.reshape(-1, 1)  # (74581, 1) 형태\n",
    "\n",
    "# 2. 학습용 데이터 준비: 시퀀스를 나누어 학습과 예측에 사용\n",
    "sequence_length = 3000  # 한 번에 입력할 시퀀스 길이\n",
    "future_length = 300  # 예측할 미래 시퀀스 길이\n",
    "\n",
    "# 입력 시퀀스를 만들기 위한 함수\n",
    "def create_sequences(data, sequence_length, future_length):\n",
    "    X, y = [], []\n",
    "    for i in range(len(data) - sequence_length - future_length):\n",
    "        X.append(data[i:i + sequence_length])\n",
    "        y.append(data[i + sequence_length:i + sequence_length + future_length])\n",
    "    return np.array(X), np.array(y)\n",
    "\n",
    "# X_train: 시퀀스 입력, y_train: 미래 예측값\n",
    "X_train, y_train = create_sequences(data, sequence_length, future_length)\n",
    "\n",
    "# 3. Transformer 모델 구성\n",
    "class TransformerBlock(tf.keras.layers.Layer):\n",
    "    def __init__(self, embed_dim, num_heads):\n",
    "        super(TransformerBlock, self).__init__()\n",
    "        self.att = tf.keras.layers.MultiHeadAttention(num_heads=num_heads, key_dim=embed_dim)\n",
    "        self.ffn = tf.keras.Sequential([\n",
    "            tf.keras.layers.Dense(embed_dim, activation=\"relu\"),\n",
    "            tf.keras.layers.Dense(embed_dim)\n",
    "        ])\n",
    "        self.layernorm1 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n",
    "        self.layernorm2 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n",
    "        self.add = tf.keras.layers.Add()\n",
    "\n",
    "    def call(self, inputs):\n",
    "        attn_output = self.att(inputs, inputs)\n",
    "        out1 = self.add([inputs, attn_output])  # Skip connection\n",
    "        out1 = self.layernorm1(out1)  # Normalization after attention\n",
    "        ffn_output = self.ffn(out1)\n",
    "        ffn_output = self.layernorm2(self.add([out1, ffn_output]))  # Skip connection\n",
    "        return ffn_output\n",
    "\n",
    "class PositionalEncoding(tf.keras.layers.Layer):\n",
    "    def __init__(self, sequence_length, embed_dim):\n",
    "        super(PositionalEncoding, self).__init__()\n",
    "        self.positional_encoding = self.positional_encoding_matrix(sequence_length, embed_dim)\n",
    "\n",
    "    def positional_encoding_matrix(self, sequence_length, embed_dim):\n",
    "        angle_rads = self.get_angles(np.arange(sequence_length)[:, np.newaxis],\n",
    "                                     np.arange(embed_dim)[np.newaxis, :],\n",
    "                                     embed_dim)\n",
    "        angle_rads[:, 0::2] = np.sin(angle_rads[:, 0::2])  # apply sin to even indices\n",
    "        angle_rads[:, 1::2] = np.cos(angle_rads[:, 1::2])  # apply cos to odd indices\n",
    "        return tf.cast(angle_rads[np.newaxis, ...], dtype=tf.float32)\n",
    "\n",
    "    def get_angles(self, position, i, d_model):\n",
    "        angle_rates = 1 / np.power(10000, (2 * (i//2)) / np.float32(d_model))\n",
    "        return position * angle_rates\n",
    "\n",
    "    def call(self, inputs):\n",
    "        return inputs + self.positional_encoding[:, :tf.shape(inputs)[1], :]\n",
    "\n",
    "# 입력 시퀀스 형태 정의\n",
    "sequence_length = 3000\n",
    "embed_dim = 16  # 임베딩 차원\n",
    "num_heads = 2   # 멀티헤드 어텐션의 헤드 수\n",
    "\n",
    "inputs = tf.keras.layers.Input(shape=(sequence_length, 1))  # (3000, 1)\n",
    "\n",
    "# Positional Encoding 적용\n",
    "pos_encoding = PositionalEncoding(sequence_length, embed_dim)(inputs)\n",
    "\n",
    "# 임베딩 차원으로 변환\n",
    "embedded_inputs = tf.keras.layers.Dense(embed_dim)(inputs)\n",
    "\n",
    "# Transformer 블록 적용\n",
    "transformer_block = TransformerBlock(embed_dim, num_heads)(embedded_inputs)\n",
    "\n",
    "# 예측할 미래 값(300분)\n",
    "outputs = tf.keras.layers.Dense(1)(transformer_block[:, -future_length:, :])\n",
    "\n",
    "# 모델 생성\n",
    "model = tf.keras.Model(inputs=inputs, outputs=outputs)\n",
    "model.compile(optimizer='adam', loss='mse')\n",
    "\n",
    "# 4. 모델 학습\n",
    "model.fit(X_train, y_train, epochs=10, batch_size=32)\n",
    "\n",
    "# 5. 예측 (새로운 입력 데이터로 예측)\n",
    "y_pred = model.predict(X_train[-1].reshape(1, sequence_length, 1))  # 마지막 시퀀스로 예측\n",
    "print(\"Predicted values for the next 300 minutes:\", y_pred)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "model(techross)",
   "language": "python",
   "name": "model"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
