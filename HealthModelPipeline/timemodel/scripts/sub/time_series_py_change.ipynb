{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "953af58d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# moduel\n",
    "from my_package.select_dataset_all import get_all_dataframe_from_database\n",
    "\n",
    "# basic\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "\n",
    "# visualize\n",
    "import matplotlib.pyplot as plt  \n",
    "\n",
    "# learning\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, LSTM\n",
    "\n",
    "# math\n",
    "from scipy.stats import linregress\n",
    "from statsmodels.tsa.seasonal import seasonal_decompose"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "522ef20a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load ship history\n",
    "ship_info = get_all_dataframe_from_database('shipinfo')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a6e67e71",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_electrode_data():\n",
    "    \"\"\" 데이터 로드 및 전처리\n",
    "    \"\"\"\n",
    "    \n",
    "    # 데이터 로드\n",
    "    data = get_all_dataframe_from_database('tc_ai_current_system_health')\n",
    "    \n",
    "    # 정제\n",
    "    data  = data[data['ELECTRODE_EFFICIENCY'].notna()]\n",
    "    data = data[(data['ELECTRODE_EFFICIENCY']>-80)]\n",
    "    data = data.drop_duplicates()\n",
    "    \n",
    "    # 결측치 제거\n",
    "    data = data.dropna()\n",
    "\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "db7d195b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_data(data,ship_id):\n",
    "\n",
    "    # 선박 선택 \n",
    "    electrod_df = data[data['SHIP_ID']==ship_id]\n",
    "\n",
    "\n",
    "    # 순서 정렬\n",
    "    electrod_df = electrod_df.sort_values(by=['DATA_TIME'])\n",
    "\n",
    "\n",
    "    # 인덱스 재 설정\n",
    "    electrod_df = electrod_df.reset_index(drop=True)\n",
    "\n",
    "    # 중복 값 제거\n",
    "    electrod_df.drop_duplicates()\n",
    "    \n",
    "    return electrod_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bd61f0b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_model_from_pickle(file_path):\n",
    "    \"\"\"\n",
    "    피클 파일에서 모델을 로드하는 함수.\n",
    "    \n",
    "    Parameters:\n",
    "    - file_path: str, 피클 파일 경로\n",
    "    \n",
    "    Returns:\n",
    "    - model: 피클 파일에서 로드된 모델\n",
    "    \"\"\"\n",
    "    try:\n",
    "        with open(file_path, 'rb') as file:\n",
    "            model = pickle.load(file)\n",
    "        print(f\"모델이 성공적으로 '{file_path}'에서 로드되었습니다.\")\n",
    "        return model\n",
    "    except FileNotFoundError:\n",
    "        print(f\"에러: '{file_path}' 파일을 찾을 수 없습니다.\")\n",
    "    except Exception as e:\n",
    "        print(f\"에러 발생: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "93da2eec",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_model_from_pickle(model_name,model):\n",
    "    with open(model_name, 'wb') as file:\n",
    "        pickle.dump(model, file)\n",
    "        \n",
    "    print(f\"모델이 {model_name}.pkl 파일로 저장되었습니다.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "870421d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_ship(ship_name):\n",
    "    ship_df = ship_info[ship_info['ship_name']==ship_name] \n",
    "    ship_id = ship_df['ship_id']\n",
    "    \n",
    "    return ship_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5d897e91",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_time_series(data):\n",
    "    # Plotting the line graph for ELECTRODE_EFFICIENCY\n",
    "\n",
    "    # Calculating the moving average (window size of 5, can be adjusted)\n",
    "    data['Moving_Average'] = data['ELECTRODE_EFFICIENCY'].rolling(window=30).mean()\n",
    "\n",
    "\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    plt.plot(data['ELECTRODE_EFFICIENCY'], linestyle='-',label='Electrode Efficiency',color='orange')\n",
    "    plt.plot(data['Moving_Average'], linestyle='--', color='red', label='Moving Average (5)')\n",
    "\n",
    "    # 12000마다 수직선 그리기\n",
    "    for i in range(0, len(data), 12000):\n",
    "        plt.axvline(x=i, color='green', linestyle='--', linewidth=0.7)\n",
    "\n",
    "    plt.title('Electrode Efficiency Over Time')\n",
    "    plt.ylabel('Electrode Efficiency')\n",
    "    plt.grid(True)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e830316b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_trend_by_section(df):\n",
    "    \n",
    "    # 슬라이딩 윈도우 설정\n",
    "    window_size = 1000  # 각 구간의 크기\n",
    "    step_size = 100    # 윈도우 이동 간격\n",
    "    results = []\n",
    "\n",
    "    # 슬라이딩 윈도우를 사용하여 구간별 감소 여부 파악\n",
    "    for start in range(0, len(df) - window_size + 1, step_size):\n",
    "        end = start + window_size\n",
    "        window_data = df.iloc[start:end]\n",
    "        x = range(window_size)  # 윈도우 내 인덱스\n",
    "        y = window_data['ELECTRODE_EFFICIENCY']\n",
    "        slope, intercept, r_value, p_value, std_err = linregress(x, y)\n",
    "\n",
    "        # 감소 경향 확인\n",
    "        is_decreasing = slope < 0  # 기울기가 음수이면 감소 경향\n",
    "        results.append({\n",
    "            'Start_Time': window_data['DATA_TIME'].iloc[0],\n",
    "            'End_Time': window_data['DATA_TIME'].iloc[-1],\n",
    "            'Slope': slope,\n",
    "            'Is_Decreasing': is_decreasing\n",
    "        })\n",
    "\n",
    "    # 결과 데이터프레임 생성\n",
    "    results_df = pd.DataFrame(results)\n",
    "\n",
    "    # 감소 경향이 있는 구간 필터링\n",
    "    decreasing_segments = results_df[results_df['Is_Decreasing']]\n",
    "\n",
    "    # 감소 경향이 있는 구간 출력\n",
    "    print(\"감소 경향이 있는 구간:\")\n",
    "    print(decreasing_segments)\n",
    "\n",
    "    # 감소 경향이 있는 일부 구간 시각화\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    for index, row in decreasing_segments.tail(5).iterrows():  # 첫 5개 구간만 시각화\n",
    "        window_data = df[(df['DATA_TIME'] >= row['Start_Time']) & (df['DATA_TIME'] <= row['End_Time'])]\n",
    "        plt.plot(window_data['DATA_TIME'], window_data['ELECTRODE_EFFICIENCY'], label=f\"구간 {row['Start_Time']} - {row['End_Time']}\")\n",
    "\n",
    "    plt.title('구간별 감소 경향 분석 (일부 구간)')\n",
    "    plt.xlabel('Time')\n",
    "    plt.ylabel('Efficiency')\n",
    "    plt.grid(True)\n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fd1164b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_train_dataset(data):\n",
    "    # 예시 데이터프레임 생성 (실제 데이터로 대체하세요)\n",
    "    # 여기서는 ELECTRODE_EFFICIENCY를 사용한다고 가정\n",
    "\n",
    "    # 데이터 스케일링\n",
    "    scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "    scaled_data = scaler.fit_transform(data[['Moving_Average']])\n",
    "\n",
    "    # 시계열 데이터 준비 함수\n",
    "    def create_sequences(data, time_steps=100):\n",
    "        X, y = [], []\n",
    "        for i in range(len(data) - time_steps):\n",
    "            X.append(data[i:i + time_steps, 0])\n",
    "            y.append(data[i + time_steps, 0])\n",
    "        return np.array(X), np.array(y)\n",
    "\n",
    "    # 시계열 길이 설정 및 데이터 분할\n",
    "    time_steps = 10\n",
    "    X, y = create_sequences(scaled_data, time_steps)\n",
    "\n",
    "    # 데이터 형태 조정 (LSTM input 형식)\n",
    "    X = X.reshape((X.shape[0], X.shape[1], 1))\n",
    "\n",
    "    # 데이터셋 분할 (80% 학습, 20% 테스트)\n",
    "    train_size = int(len(X) * 0.8)\n",
    "    X_train, X_test = X[:train_size], X[train_size:]\n",
    "    y_train, y_test = y[:train_size], y[train_size:]\n",
    "    \n",
    "    return X_train,X_test,y_train,y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7b7b6a49",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_lstm_obj(X_train,y_train):\n",
    "\n",
    "    # NNAR 모델 정의\n",
    "    model = Sequential()\n",
    "    model.add(LSTM(50, activation='relu', input_shape=(time_steps, 1)))\n",
    "    model.add(Dense(1))\n",
    "    model.compile(optimizer='adam', loss='mse')\n",
    "\n",
    "    # 모델 학습\n",
    "    model.fit(X_train, y_train, epochs=20, batch_size=32, validation_split=0.2, verbose=1)\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "678d890d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def  plot_predict_values(model,X_test,y_train,y_test):\n",
    "\n",
    "        # 예측 수행\n",
    "        predictions = model.predict(X_test)\n",
    "        predictions = scaler.inverse_transform(predictions.reshape(-1, 1))\n",
    "\n",
    "        # 실제 값과 예측 값 비교\n",
    "\n",
    "        # 실제 값 재조정 (Rescale)\n",
    "        y_train_rescaled = scaler.inverse_transform(y_train.reshape(-1, 1))\n",
    "        y_test_rescaled = scaler.inverse_transform(y_test.reshape(-1, 1))\n",
    "        #predicted_values_rescaled = scaler.inverse_transform(np.array(predicted_values).reshape(-1, 1))\n",
    "\n",
    "        # 결과 시각화\n",
    "        import matplotlib.pyplot as plt\n",
    "\n",
    "        plt.figure(figsize=(14, 6))\n",
    "\n",
    "        # 학습 데이터의 실제 값 시각화\n",
    "        plt.plot(y_train_rescaled, label='Train Actual', color='blue')\n",
    "\n",
    "        plt.plot(range(len(y_train_rescaled), len(y_train_rescaled) + len(y_test_rescaled)), y_test_rescaled, label='Test Actual')\n",
    "        plt.plot(range(len(y_train_rescaled), len(y_train_rescaled) + len(y_test_rescaled)), predictions, label='Predicted', linestyle='--')\n",
    "        #plt.plot(range(len(y_train_rescaled) + len(y_test_rescaled), len(y_train_rescaled) + len(y_test_rescaled)+2000),predicted_values_rescaled,label='Predicted Over', linestyle='--')\n",
    "\n",
    "        plt.title('NNAR Model Predictions')\n",
    "        plt.xlabel('Time Steps')\n",
    "        plt.ylabel('Efficiency') #24살\n",
    "        plt.legend()\n",
    "        plt.show()\n",
    "        \n",
    "        return y_test_rescaled, predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "003f96c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_evaluation(y_test_rescaled,predictions):\n",
    "    # 평가 지표 계산\n",
    "\n",
    "    mse = mean_squared_error(y_test_rescaled, predictions)\n",
    "    rmse = np.sqrt(mse)\n",
    "\n",
    "    # 결과 출력\n",
    "    print(f\"Root Mean Squared Error (RMSE): {rmse}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "348e4e46",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_step_by_step_prediction(scaled_data,model,time_steps):\n",
    "\n",
    "    # 단계별 예측을 통한 6000분 후 예측\n",
    "    # 초기 입력 데이터로 마지막 10분 데이터 사용\n",
    "    # 설정\n",
    "    time_steps = 100  # 10분 동안의 데이터를 사용하여 예측\n",
    "\n",
    "    predicted_values = []\n",
    "    current_sequence = scaled_data[-time_steps:]  # 마지막 10분간의 데이터\n",
    "\n",
    "    for _ in range(2000):\n",
    "        # LSTM이 요구하는 입력 형태로 변환\n",
    "        current_sequence_reshaped = current_sequence.reshape(1, time_steps, 1)\n",
    "\n",
    "        # 다음 값을 예측\n",
    "        predicted_value = model.predict(current_sequence_reshaped)[0, 0]\n",
    "        predicted_values.append(predicted_value)\n",
    "\n",
    "        # 예측된 값을 현재 시퀀스에 추가하고, 맨 앞의 값을 제거\n",
    "        current_sequence = np.append(current_sequence[1:], predicted_value)\n",
    "\n",
    "    # 2000분 후 예측된 마지막 값 출력\n",
    "    #print(f\"200분 후 예측된 값: {predicted_values[-1]}\")\n",
    "    \n",
    "    return predicted_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "df620c33",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. Seasonal Decomposition (Optional if you suspect seasonal pattern)\n",
    "def plot_seasonal(data):\n",
    "    result = seasonal_decompose(data['Moving_Average'].dropna(), model='additive', period=1000)  # Adjust period as needed\n",
    "    result.plot()\n",
    "    plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "model",
   "language": "python",
   "name": "model"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
